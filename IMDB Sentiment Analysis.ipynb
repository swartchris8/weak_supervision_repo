{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f5142f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import skweak\n",
    "from skweak import utils\n",
    "\n",
    "from typing import Iterable, Optional, Sequence, Tuple\n",
    "\n",
    "from spacy.tokens import Doc, Span  # type: ignore\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e050257",
   "metadata": {},
   "source": [
    "!pip install datasets\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a7490",
   "metadata": {},
   "source": [
    "### Load imdb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a851b649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data_sci_global_summit/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset imdb (/Users/chris/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "100%|██████████| 3/3 [00:00<00:00, 527.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c82e997-6fbc-43ab-9495-42f9b7b39fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][0][\"label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7b45521-b2dc-426a-b1d6-c68a63b305d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0][\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f2d98",
   "metadata": {},
   "source": [
    "### Dataset labels\n",
    "\n",
    "0 -- Negative -- 50%\n",
    "\n",
    "1 -- Positive -- 50%\n",
    "\n",
    "-1 -- Unlabelled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82cf0b2-9af0-46a2-8287-62c83101d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "881076eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_model_name = \"en_core_web_sm\" # needed for DocBin -> Doc process\n",
    "\n",
    "nlp = spacy.load(spacy_model_name)   # We load an English-language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c39514c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"This is a test.\")\n",
    "\n",
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "889e94b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_prep(data_dict):\n",
    "    doc = nlp(data_dict[\"text\"])\n",
    "    doc.user_data[\"gold\"] = data_dict[\"label\"]\n",
    "    return doc\n",
    "    \n",
    "def write_dataset_to_docbin(dataset_chunk, docbin, docbin_path):\n",
    "    for data_dict in tqdm(dataset_chunk):\n",
    "        docbin.add(spacy_prep(data_dict))\n",
    "    if docbin_path:\n",
    "        docbin.to_disk(docbin_path)\n",
    "        \n",
    "def write_docs_to_docbin(docs, docbin_path):\n",
    "    docbin = DocBin(store_user_data=True)\n",
    "    for doc in docs:\n",
    "        docbin.add(doc)\n",
    "    docbin.to_disk(docbin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efcf1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_doc_bin = DocBin(store_user_data=True)\n",
    "# unsupervised_doc_bin = DocBin(store_user_data=True)\n",
    "# test_doc_bin = DocBin(store_user_data=True)\n",
    "\n",
    "\n",
    "# write_dataset_to_docbin(dataset[\"train\"], train_doc_bin, \"sentiment_docbin/train.docbin\")\n",
    "\n",
    "# write_dataset_to_docbin(dataset[\"unsupervised\"], unsupervised_doc_bin, \"sentiment_docbin/unsupervised.docbin\")\n",
    "\n",
    "# write_dataset_to_docbin(dataset[\"test\"], test_doc_bin, \"sentiment_docbin/test.docbin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22b154e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = list(utils.docbin_reader(\"sentiment_docbin/train.docbin\", spacy_model_name=spacy_model_name))\n",
    "\n",
    "test_docs = list(utils.docbin_reader(\"sentiment_docbin/test.docbin\", spacy_model_name=spacy_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3531763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_labels(docs):\n",
    "    return [doc.user_data[\"gold\"] for doc in docs]\n",
    "\n",
    "train_true = gold_labels(train_docs)\n",
    "test_true = gold_labels(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb7c864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00217f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup positive mock annotator\n",
      "Setup negative mock annotator\n"
     ]
    }
   ],
   "source": [
    "from typing import Iterable, Optional, Sequence, Tuple\n",
    "\n",
    "from spacy.tokens import Doc, Span  # type: ignore\n",
    "\n",
    "class MockPositiveAnnotator(skweak.base.SpanAnnotator):\n",
    "    \"\"\"Annotate everything positive\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        name = \"mock_positive_annotator\"\n",
    "        super(MockPositiveAnnotator, self).__init__(name)\n",
    "\n",
    "        print(\"Setup positive mock annotator\")\n",
    "\n",
    "    def find_spans(self, doc: Doc) -> Iterable[Tuple[int, int, str]]:\n",
    "        yield 0, len(doc), \"1\"\n",
    "        \n",
    "        \n",
    "class MockNegativeAnnotator(skweak.base.SpanAnnotator):\n",
    "    \"\"\"Annotate everything negative\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        name = \"mock_negative_annotator\"\n",
    "        super(MockNegativeAnnotator, self).__init__(name)\n",
    "\n",
    "        print(\"Setup negative mock annotator\")\n",
    "\n",
    "    def find_spans(self, doc: Doc) -> Iterable[Tuple[int, int, str]]:\n",
    "        yield 0, len(doc), \"0\"\n",
    "        \n",
    "mock_positive_annotator = MockPositiveAnnotator()\n",
    "mock_negative_annotator = MockNegativeAnnotator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cf98205",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_voter = skweak.voting.SequentialMajorityVoter(\"maj_voter\", labels=[\"0\", \"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32648716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<skweak.base.CombinedAnnotator at 0x7faf00645060>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combi_mock = skweak.base.CombinedAnnotator()\n",
    "combi_mock.add_annotator(mock_positive_annotator)\n",
    "combi_mock.add_annotator(mock_negative_annotator)\n",
    "combi_mock.add_annotator(majority_voter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a20694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53646689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mock_train_results = list(combi_mock.pipe(train_docs))\n",
    "# mock_test_results = list(combi_mock.pipe(train_docs))\n",
    "\n",
    "# write_docs_to_docbin(mock_train_results, \"mock_train.docbin\")\n",
    "# write_docs_to_docbin(mock_train_results, \"mock_test.docbin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50d06a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_train_results = list(utils.docbin_reader(\"mock_train.docbin\", spacy_model_name=spacy_model_name))\n",
    "\n",
    "mock_test_results = list(utils.docbin_reader(\"mock_test.docbin\", spacy_model_name=spacy_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f78940b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5dda227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_train_results[0].spans[\"mock_positive_annotator\"][0].label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b022c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_labels(docs, agg_name=\"maj_voter\"):\n",
    "    return [int(doc.spans[agg_name][0].label_) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d4b7a10",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mock_train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mpredicted_labels\u001b[49m(mock_train_results)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted_labels' is not defined"
     ]
    }
   ],
   "source": [
    "mock_train_labels = predicted_labels(mock_train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fba5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_test_labels = predicted_labels(mock_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033f27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    print(f\"\"\"Precision {precision_score(y_true, y_pred)},\n",
    "    Recall {recall_score(y_true, y_pred)},\n",
    "    F1 {f1_score(y_true, y_pred)}\n",
    "    \n",
    "    ---\n",
    "    Confusion matrix\n",
    "    {confusion_matrix(y_true, y_pred)}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7912fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(train_true, mock_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cfe53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(test_true, mock_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646a2ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "y_true = [0, 1, 1, 0, 1, 1]\n",
    "y_pred = [0, 0, 0, 0, 0, 0]\n",
    "precision_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ee23b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6538b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skweak import gazetteers\n",
    "\n",
    "NEGATIVE_WORDS = [\"unhappy\", \"sad\", \"disappointing\", \"bad\"]\n",
    "NEGATIVE_WORDS = [[word] for word in NEGATIVE_WORDS]\n",
    "\n",
    "\n",
    "POSITIVE_WORDS = [\"happy\", \"great\", \"awesome\", \"amazing\", \"good\", \"fun\"]\n",
    "POSITIVE_WORDS = [[word] for word in POSITIVE_WORDS]\n",
    "# NEGATIVE_WORDS = [\"unhappy\", ]\n",
    "\n",
    "positive_trie = gazetteers.Trie(POSITIVE_WORDS)\n",
    "\n",
    "gazetteer = gazetteers.GazetteerAnnotator(\"sent_gazetteer\", {1:positive_trie})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0eb755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GazetteerDocDetector(skweak.base.SpanAnnotator):\n",
    "    def __init__(self):\n",
    "        super(GazetteerDocDetector, self).__init__(\"gazetteer_doc_detector\")\n",
    "\n",
    "    def find_spans(self, doc):\n",
    "        gazetteer_score = 0\n",
    "        for start, end, score in gazetteer.find_spans(doc):\n",
    "            gazetteer_score += score \n",
    "        if 0 < gazetteer_score:\n",
    "            yield 0, len(doc), \"1\"\n",
    "        # TODO set default to -1 (unlabelled) or 0 (negative)?\n",
    "        else:\n",
    "            yield 0, len(doc), \"0\"\n",
    "        \n",
    "gazetteer_doc_detector = GazetteerDocDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e39051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_voter = skweak.voting.SequentialMajorityVoter(\"maj_voter\", labels=[\"0\", \"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e636c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_sentiment = skweak.base.CombinedAnnotator()\n",
    "combined_sentiment.add_annotator(gazetteer_doc_detector)\n",
    "\n",
    "combined_sentiment.add_annotator(majority_voter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf97c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaz_train_docs = list(combined_sentiment.pipe(train_docs))\n",
    "# write_docs_to_docbin(gaz_train_docs, \"trained_v1.docbin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab6f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaz_docs_test = list(combined_sentiment.pipe(test_docs))\n",
    "write_docs_to_docbin(gaz_docs_test, \"gaz_docs_test.docbin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc63a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaz_docs_train = list(utils.docbin_reader(\"trained_v1.docbin\", spacy_model_name=spacy_model_name))\n",
    "\n",
    "gaz_docs_test = list(utils.docbin_reader(\"gaz_docs_test.docbin\", spacy_model_name=spacy_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1645d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(train_true, gaz_docs_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2451e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaz_docs_train_labels = predicted_labels(gaz_docs_train)\n",
    "gaz_docs_test_labels = predicted_labels(gaz_docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_metrics(train_true, gaz_docs_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00516f1-cfd5-48c2-81e9-eb8124ec47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = [doc.text for doc in gaz_train_docs]\n",
    "train_weak_labels = gaz_docs_train_labels\n",
    "\n",
    "test_texts = [doc.text for doc in gaz_docs_test]\n",
    "test_weak_labels = gaz_docs_test\n",
    "\n",
    "train_df = pd.DataFrame(list(zip(train_texts, train_weak_labels)),\n",
    "               columns =['text', 'label'])\n",
    "\n",
    "train_df.to_json(\"weak_imdb_train.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "test_df = pd.DataFrame(list(zip(train_texts, train_weak_labels)),\n",
    "               columns =['text', 'label'])\n",
    "\n",
    "test_df.to_json(\"weak_imdb_test.jsonl\", orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72d8b04-c685-4ec1-9705-977f45c840b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_train_dataset = load_dataset(\"json\", data_files=\"weak_imdb_train.jsonl\", split=\"train\")\n",
    "\n",
    "weak_test_dataset = load_dataset(\"json\", data_files=\"weak_imdb_test.jsonl\", split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb87d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy init fill-config ./base_config.cfg ./config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6587391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d109dc-e5ef-4345-9d91-a099c63ea273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d73bc6d-e009-479b-9c3e-ef68b6214a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c25d6-44f4-4639-82ef-71fe54e76258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93f84f-7997-4c0d-a75a-b687801d3d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd401c6-13f0-4ab7-bb17-170e15dbc1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea68ad8-f826-4bd2-a1da-58103aa2f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f83b7-8f62-4d18-9814-155727fa0ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
