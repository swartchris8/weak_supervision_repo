{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f5142f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import skweak\n",
    "from skweak import utils\n",
    "\n",
    "from typing import Iterable, Optional, Sequence, Tuple\n",
    "\n",
    "from spacy.tokens import Doc, Span  # type: ignore\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e050257",
   "metadata": {},
   "source": [
    "!pip install datasets\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a7490",
   "metadata": {},
   "source": [
    "### Load imdb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a851b649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/Users/chris/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n",
      "100%|██████████| 3/3 [00:00<00:00, 560.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f2d98",
   "metadata": {},
   "source": [
    "### Dataset labels\n",
    "\n",
    "0 -- Negative -- 50%\n",
    "\n",
    "1 -- Positive -- 50%\n",
    "\n",
    "-1 -- Unlabelled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82cf0b2-9af0-46a2-8287-62c83101d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download en_core_web_sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "881076eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_model_name = \"en_core_web_sm\" # needed for DocBin -> Doc process\n",
    "\n",
    "nlp = spacy.load(spacy_model_name)   # We load an English-language model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c39514c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"This is a test.\")\n",
    "\n",
    "doc.text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "889e94b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_prep(data_dict):\n",
    "    doc = nlp(data_dict[\"text\"])\n",
    "    doc.user_data[\"gold\"] = data_dict[\"label\"]\n",
    "    return doc\n",
    "    \n",
    "def write_dataset_to_docbin(dataset_chunk, docbin, docbin_path):\n",
    "    for data_dict in tqdm(dataset_chunk):\n",
    "        docbin.add(spacy_prep(data_dict))\n",
    "    if docbin_path:\n",
    "        docbin.to_disk(docbin_path)\n",
    "        \n",
    "def write_docs_to_docbin(docs, docbin_path):\n",
    "    docbin = DocBin(store_user_data=True)\n",
    "    for doc in docs:\n",
    "        docbin.add(doc)\n",
    "    docbin.to_disk(docbin_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6123baaf-db4b-4b33-8ed3-814bef27e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir sentiment_docbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efcf1b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [17:07<00:00, 24.33it/s]\n"
     ]
    }
   ],
   "source": [
    "train_doc_bin = DocBin(store_user_data=True)\n",
    "write_dataset_to_docbin(dataset[\"train\"], train_doc_bin, \"sentiment_docbin/train.docbin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a69daff-4d2e-4809-ac01-449b7248019e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [17:07<00:00, 24.34it/s]\n"
     ]
    }
   ],
   "source": [
    "test_doc_bin = DocBin(store_user_data=True)\n",
    "write_dataset_to_docbin(dataset[\"test\"], test_doc_bin, \"sentiment_docbin/test.docbin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22b154e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "train_docs = list(utils.docbin_reader(\"sentiment_docbin/train.docbin\", spacy_model_name=spacy_model_name))\n",
    "\n",
    "test_docs = list(utils.docbin_reader(\"sentiment_docbin/test.docbin\", spacy_model_name=spacy_model_name))\n",
    "\n",
    "print(len(train_docs))\n",
    "print(len(test_docs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3531763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold_labels(docs):\n",
    "    return [doc.user_data[\"gold\"] for doc in docs]\n",
    "\n",
    "train_true = gold_labels(train_docs)\n",
    "test_true = gold_labels(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb7c864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00217f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup positive mock annotator\n",
      "Setup negative mock annotator\n"
     ]
    }
   ],
   "source": [
    "from typing import Iterable, Optional, Sequence, Tuple\n",
    "\n",
    "from spacy.tokens import Doc, Span  # type: ignore\n",
    "\n",
    "class MockPositiveAnnotator(skweak.base.SpanAnnotator):\n",
    "    \"\"\"Annotate everything positive\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        name = \"mock_positive_annotator\"\n",
    "        super(MockPositiveAnnotator, self).__init__(name)\n",
    "\n",
    "        print(\"Setup positive mock annotator\")\n",
    "\n",
    "    def find_spans(self, doc: Doc) -> Iterable[Tuple[int, int, str]]:\n",
    "        yield 0, len(doc), \"1\"\n",
    "        \n",
    "        \n",
    "class MockNegativeAnnotator(skweak.base.SpanAnnotator):\n",
    "    \"\"\"Annotate everything negative\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        name = \"mock_negative_annotator\"\n",
    "        super(MockNegativeAnnotator, self).__init__(name)\n",
    "\n",
    "        print(\"Setup negative mock annotator\")\n",
    "\n",
    "    def find_spans(self, doc: Doc) -> Iterable[Tuple[int, int, str]]:\n",
    "        yield 0, len(doc), \"0\"\n",
    "        \n",
    "mock_positive_annotator = MockPositiveAnnotator()\n",
    "mock_negative_annotator = MockNegativeAnnotator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cf98205",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_voter = skweak.voting.SequentialMajorityVoter(\"maj_voter\", labels=[\"0\", \"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "32648716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<skweak.base.CombinedAnnotator at 0x373d15880>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combi_mock = skweak.base.CombinedAnnotator()\n",
    "combi_mock.add_annotator(mock_positive_annotator)\n",
    "combi_mock.add_annotator(mock_negative_annotator)\n",
    "combi_mock.add_annotator(majority_voter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a20694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53646689",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_train_results = list(combi_mock.pipe(train_docs))\n",
    "mock_test_results = list(combi_mock.pipe(train_docs))\n",
    "\n",
    "write_docs_to_docbin(mock_train_results, \"mock_train.docbin\")\n",
    "write_docs_to_docbin(mock_train_results, \"mock_test.docbin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50d06a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_train_results = list(utils.docbin_reader(\"mock_train.docbin\", spacy_model_name=spacy_model_name))\n",
    "\n",
    "mock_test_results = list(utils.docbin_reader(\"mock_test.docbin\", spacy_model_name=spacy_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f78940b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5dda227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_train_results[0].spans[\"mock_positive_annotator\"][0].label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b022c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_labels(docs, agg_name=\"maj_voter\"):\n",
    "    return [int(doc.spans[agg_name][0].label_) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d4b7a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_train_labels = predicted_labels(mock_train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4fba5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_test_labels = predicted_labels(mock_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "033f27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    print(f\"\"\"Precision {precision_score(y_true, y_pred, average=\"macro\")},\n",
    "    Recall {recall_score(y_true, y_pred, average=\"macro\")},\n",
    "    F1 {f1_score(y_true, y_pred, average=\"macro\")}\n",
    "    \n",
    "    ---\n",
    "    Confusion matrix\n",
    "    {confusion_matrix(y_true, y_pred)}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7912fac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.0,\n",
      "    Recall 0.0,\n",
      "    F1 0.0\n",
      "    \n",
      "    ---\n",
      "    Confusion matrix\n",
      "    [[12500     0]\n",
      " [12500     0]]\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data_sci_global_summit/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(train_true, mock_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89cfe53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.0,\n",
      "    Recall 0.0,\n",
      "    F1 0.0\n",
      "    \n",
      "    ---\n",
      "    Confusion matrix\n",
      "    [[12500     0]\n",
      " [12500     0]]\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data_sci_global_summit/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(test_true, mock_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "646a2ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data_sci_global_summit/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "y_true = [0, 1, 1, 0, 1, 1]\n",
    "y_pred = [0, 0, 0, 0, 0, 0]\n",
    "precision_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ee23b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6538b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skweak import gazetteers\n",
    "\n",
    "NEGATIVE_WORDS = [\"unhappy\", \"sad\", \"disappointing\", \"bad\"]\n",
    "NEGATIVE_WORDS = [[word] for word in NEGATIVE_WORDS]\n",
    "\n",
    "\n",
    "POSITIVE_WORDS = [\"happy\", \"great\", \"awesome\", \"amazing\", \"good\", \"fun\"]\n",
    "POSITIVE_WORDS = [[word] for word in POSITIVE_WORDS]\n",
    "# NEGATIVE_WORDS = [\"unhappy\", ]\n",
    "\n",
    "positive_trie = gazetteers.Trie(POSITIVE_WORDS)\n",
    "negative_trie = gazetteers.Trie(NEGATIVE_WORDS)\n",
    "\n",
    "gazetteer = gazetteers.GazetteerAnnotator(\"sent_gazetteer\", {1:positive_trie, -1:negative_trie})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ac0eb755",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GazetteerDocDetector(skweak.base.SpanAnnotator):\n",
    "    def __init__(self):\n",
    "        super(GazetteerDocDetector, self).__init__(\"gazetteer_doc_detector\")\n",
    "\n",
    "    def find_spans(self, doc):\n",
    "        gazetteer_score = 0\n",
    "        for start, end, score in gazetteer.find_spans(doc):\n",
    "            gazetteer_score += score \n",
    "        if 0 < gazetteer_score:\n",
    "            yield 0, len(doc), \"1\"\n",
    "        # TODO set default to -1 (unlabelled) or 0 (negative)?\n",
    "        elif gazetteer_score < 0:\n",
    "            yield 0, len(doc), \"0\"\n",
    "        else:\n",
    "            yield 0, len(doc), \"-1\"\n",
    "        \n",
    "gazetteer_doc_detector = GazetteerDocDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e39051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_voter = skweak.voting.SequentialMajorityVoter(\"maj_voter\", labels=[\"0\", \"1\", \"-1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9e636c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<skweak.base.CombinedAnnotator at 0x2c32684c0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_sentiment = skweak.base.CombinedAnnotator()\n",
    "combined_sentiment.add_annotator(gazetteer_doc_detector)\n",
    "\n",
    "combined_sentiment.add_annotator(majority_voter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fbf97c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaz_train_docs = list(combined_sentiment.pipe(train_docs))\n",
    "write_docs_to_docbin(gaz_train_docs, \"trained_v1.docbin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1ab6f040",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaz_docs_test = list(combined_sentiment.pipe(test_docs))\n",
    "write_docs_to_docbin(gaz_docs_test, \"gaz_docs_test.docbin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4bc63a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaz_docs_train = list(utils.docbin_reader(\"trained_v1.docbin\", spacy_model_name=spacy_model_name))\n",
    "\n",
    "gaz_docs_test = list(utils.docbin_reader(\"gaz_docs_test.docbin\", spacy_model_name=spacy_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ba2451e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaz_docs_train_labels = predicted_labels(gaz_docs_train)\n",
    "gaz_docs_test_labels = predicted_labels(gaz_docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7e6affec-019a-40a1-86c3-9b1d24cdb267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 11826, 0: 13174})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "C = Counter(gaz_docs_train_labels)\n",
    "\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f70cbbbd-36a1-49ed-9260-87d20782716f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 11621, -1: 10188, 0: 3191})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = Counter(gaz_docs_test_labels)\n",
    "\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2b1645d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.6079939780632233,\n",
      "    Recall 0.60768,\n",
      "    F1 0.6073946380905813\n",
      "    \n",
      "    ---\n",
      "    Confusion matrix\n",
      "    [[7933 4567]\n",
      " [5241 7259]]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(train_true, gaz_docs_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8745e922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0.4779863082816183,\n",
      "    Recall 0.2602933333333333,\n",
      "    F1 0.3085785817867689\n",
      "    \n",
      "    ---\n",
      "    Confusion matrix\n",
      "    [[   0    0    0]\n",
      " [5414 2613 4473]\n",
      " [4774  578 7148]]\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/data_sci_global_summit/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(test_true, gaz_docs_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e00516f1-cfd5-48c2-81e9-eb8124ec47db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_texts = [doc.text for doc in gaz_train_docs]\n",
    "train_weak_labels = gaz_docs_train_labels\n",
    "\n",
    "test_texts = [doc.text for doc in gaz_docs_test]\n",
    "test_weak_labels = gaz_docs_test\n",
    "\n",
    "train_df = pd.DataFrame(list(zip(train_texts, train_weak_labels)),\n",
    "               columns =['text', 'label'])\n",
    "\n",
    "train_df = train_df[test_df.label != -1]\n",
    "\n",
    "\n",
    "train_df.to_json(\"weak_imdb_train.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "test_df = pd.DataFrame(list(zip(train_texts, train_weak_labels)),\n",
    "               columns =['text', 'label'])\n",
    "\n",
    "test_df = test_df[test_df.label != -1]\n",
    "\n",
    "test_df.to_json(\"weak_imdb_test.jsonl\", orient=\"records\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "be54cfab-194e-451a-8525-743143174a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "         ... \n",
       "24995    True\n",
       "24996    True\n",
       "24997    True\n",
       "24998    True\n",
       "24999    True\n",
       "Name: label, Length: 25000, dtype: bool"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72d8b04-c685-4ec1-9705-977f45c840b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afb87d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy init fill-config ./base_config.cfg ./config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6587391f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d109dc-e5ef-4345-9d91-a099c63ea273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d73bc6d-e009-479b-9c3e-ef68b6214a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c25d6-44f4-4639-82ef-71fe54e76258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93f84f-7997-4c0d-a75a-b687801d3d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd401c6-13f0-4ab7-bb17-170e15dbc1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea68ad8-f826-4bd2-a1da-58103aa2f424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f83b7-8f62-4d18-9814-155727fa0ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
